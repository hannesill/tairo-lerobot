{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a policy checkpoint, you can easily control your robot with it using methods from ManipulatorRobot and the policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Do inference yourself "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this code for running inference for 60 seconds at 30 fps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Auto-correct calibration of motor 'wrist_flex' by shifting value by 1 full turns, from '-270 < 356.572265625 < 270 degrees' to '-270 < 356.572265625 < 270 degrees'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting main follower arm.\n",
      "Connecting main leader arm.\n",
      "Activating torque on main follower arm.\n",
      "Wrong motor position range detected for wrist_flex. Expected to be in nominal range of [-180, 180] degrees (a full rotation), with a maximum range of [-270, 270] degrees to account for joints that can rotate a bit more, but present value is 356.572265625 degree. This might be due to a cable connection issue creating an artificial 360 degrees jump in motor values. You need to recalibrate by running: `python lerobot/scripts/control_robot.py calibrate`\n"
     ]
    }
   ],
   "source": [
    "# First, initialize the robot\n",
    "from lerobot.common.robot_devices.robots.configs import KochRobotConfig\n",
    "from lerobot.common.robot_devices.robots.manipulator import ManipulatorRobot\n",
    "from lerobot.common.robot_devices.cameras.configs import OpenCVCameraConfig\n",
    "from lerobot.common.robot_devices.motors.configs import DynamixelMotorsBusConfig\n",
    "\n",
    "leader_config = DynamixelMotorsBusConfig(\n",
    "    port=\"/dev/tty.usbmodem58760435371\",\n",
    "    motors={\n",
    "        # name: (index, model)\n",
    "        \"shoulder_pan\": (1, \"xl330-m077\"),\n",
    "        \"shoulder_lift\": (2, \"xl330-m077\"),\n",
    "        \"elbow_flex\": (3, \"xl330-m077\"),\n",
    "        \"wrist_flex\": (4, \"xl330-m077\"),\n",
    "        \"wrist_roll\": (5, \"xl330-m077\"),\n",
    "        \"gripper\": (6, \"xl330-m077\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "follower_config = DynamixelMotorsBusConfig(\n",
    "    port=\"/dev/tty.usbmodem58760433811\",\n",
    "    motors={\n",
    "        # name: (index, model)\n",
    "        \"shoulder_pan\": (1, \"xl430-w250\"),\n",
    "        \"shoulder_lift\": (2, \"xl430-w250\"),\n",
    "        \"elbow_flex\": (3, \"xl330-m288\"),\n",
    "        \"wrist_flex\": (4, \"xl330-m288\"),\n",
    "        \"wrist_roll\": (5, \"xl330-m288\"),\n",
    "        \"gripper\": (6, \"xl330-m288\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "robot = ManipulatorRobot(\n",
    "    KochRobotConfig(\n",
    "        leader_arms={\"main\": leader_config},\n",
    "        follower_arms={\"main\": follower_config},\n",
    "        calibration_dir=\".cache/calibration/koch\",\n",
    "        cameras={\n",
    "            \"usb\": OpenCVCameraConfig(0, fps=30, width=640, height=480),\n",
    "            \"macbook\": OpenCVCameraConfig(1, fps=30, width=640, height=480),\n",
    "        },\n",
    "    )\n",
    ")\n",
    "robot.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "import time\n",
    "from lerobot.scripts.control_robot import busy_wait\n",
    "\n",
    "inference_time_s = 60\n",
    "fps = 30\n",
    "device = \"cuda\"  # TODO: On Mac, use \"mps\" or \"cpu\"\n",
    "\n",
    "ckpt_path = \"outputs/train/act_koch_test/checkpoints/last/pretrained_model\"\n",
    "policy = ACTPolicy.from_pretrained(ckpt_path)\n",
    "policy.to(device)\n",
    "\n",
    "for _ in range(inference_time_s * fps):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Read the follower state and access the frames from the cameras\n",
    "    observation = robot.capture_observation()\n",
    "\n",
    "    # Convert to pytorch format: channel first and float32 in [0,1]\n",
    "    # with batch dimension\n",
    "    for name in observation:\n",
    "        if \"image\" in name:\n",
    "            observation[name] = observation[name].type(torch.float32) / 255\n",
    "            observation[name] = observation[name].permute(2, 0, 1).contiguous()\n",
    "        observation[name] = observation[name].unsqueeze(0)\n",
    "        observation[name] = observation[name].to(device)\n",
    "\n",
    "    # Compute the next action with the policy\n",
    "    # based on the current observation\n",
    "    action = policy.select_action(observation)\n",
    "    # Remove batch dimension\n",
    "    action = action.squeeze(0)\n",
    "    # Move to cpu, if not already the case\n",
    "    action = action.to(\"cpu\")\n",
    "    # Order the robot to move\n",
    "    robot.send_action(action)\n",
    "\n",
    "    dt_s = time.perf_counter() - start_time\n",
    "    busy_wait(1 / fps - dt_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use our `record` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, when controlling your robot with your neural network, you would want to record evaluation episodes and to be able to visualize them later on, or even train on them like in Reinforcement Learning. This pretty much corresponds to recording a new dataset but with a neural network providing the actions instead of teleoperation.\n",
    "\n",
    "To this end, you can use the record function from lerobot/scripts/control_robot.py but with a policy checkpoint as input. For instance, run this command to record 10 evaluation episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python lerobot/scripts/control_robot.py \\\n",
    "  --robot.type=koch \\\n",
    "  --control.type=record \\\n",
    "  --control.fps=30 \\\n",
    "  --control.repo_id=${HF_USER}/eval_act_koch_test \\\n",
    "  --control.tags='[\"tutorial\"]' \\\n",
    "  --control.warmup_time_s=5 \\\n",
    "  --control.episode_time_s=30 \\\n",
    "  --control.reset_time_s=30 \\\n",
    "  --control.num_episodes=10 \\\n",
    "  --control.push_to_hub=true \\\n",
    "  --control.policy.path=outputs/train/act_koch_test/checkpoints/last/pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's almost the same command as previously used to record your training dataset. Two things changed:\n",
    "\n",
    "1. There is an additional `--control.policy.path` argument which indicates the path to your policy checkpoint with (e.g. `outputs/train/eval_koch_test/checkpoints/last/pretrained_model`). You can also use the model repository if you uploaded a model checkpoint to the hub (e.g. `\\${HF_USER}/act_koch_test`).\n",
    "\n",
    "2. The name of dataset begins by eval to reflect that you are running inference (e.g. `\\${HF_USER}/eval_act_koch_test`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize your evaluation afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then visualize your evaluation dataset by running the same command as for visualizing a train dataset but with the new inference dataset as argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python lerobot/scripts/visualize_dataset.py \\\n",
    "  --repo-id ${HF_USER}/eval_act_koch_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you finished the intro on setting up TaiRo's Koch v1.1, recording a dataset for it, training a policy based on imitation learning and evaluating that policy ðŸ¥³\n",
    "\n",
    "With that you are well equipped to start your own robot experiments. Let's go!! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
